
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>支持向量机SVM | 风清阳明</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="Jinwen">
    
    <meta name="description" content="支持向量机(Support Vector Machine，SVM)是最重要的分类器之一（还是加上“之一”两个字，这样保证不会错），下面开始简单推导出SVM。
SVM的别名是最大间隔分类器，这里的最大间隔指的是训练样本点到分隔超平面的间隔最大。在感知器中，没有考虑最大分隔这一条件，所以对于线性可分的数">
    
    
    
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/pacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/pacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.svg" alt="风清阳明" title="风清阳明"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="风清阳明">风清阳明</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="text" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:xiaojinwen.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2014/06/01/svm/" title="支持向量机SVM" itemprop="url">支持向量机SVM</a>
  </h1>
  <p class="article-author">By
    
      <a href="http://xiaojinwen.com" title="Jinwen">Jinwen</a>
    </p>
  <p class="article-time">
    <time datetime="2014-06-01T05:32:25.000Z" itemprop="datePublished">6月 1 2014</time>
    更新日期:<time datetime="2014-06-01T12:40:44.000Z" itemprop="dateModified">6月 1 2014</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#拉格朗日乘子法"><span class="toc-number">1.</span> <span class="toc-text">拉格朗日乘子法</span></a></li><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#原始问题"><span class="toc-number">1.1.</span> <span class="toc-text">原始问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#拉格朗日乘子法图解"><span class="toc-number">1.2.</span> <span class="toc-text">拉格朗日乘子法图解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#对偶问题"><span class="toc-number">1.3.</span> <span class="toc-text">对偶问题</span></a></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#SVM"><span class="toc-number">2.</span> <span class="toc-text">SVM</span></a></li><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#函数间隔和几何间隔"><span class="toc-number">2.1.</span> <span class="toc-text">函数间隔和几何间隔</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#间隔最大化"><span class="toc-number">2.2.</span> <span class="toc-text">间隔最大化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#对偶求解"><span class="toc-number">2.3.</span> <span class="toc-text">对偶求解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#线性不可分问题"><span class="toc-number">2.4.</span> <span class="toc-text">线性不可分问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#非线性支持向量机"><span class="toc-number">2.5.</span> <span class="toc-text">非线性支持向量机</span></a></li><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#核函数"><span class="toc-number">2.5.1.</span> <span class="toc-text">核函数</span></a></li></ol>
		</div>
		
		<p>支持向量机(Support Vector Machine，SVM)是最重要的分类器之一（还是加上“之一”两个字，这样保证不会错），下面开始简单推导出SVM。</p>
<p>SVM的别名是最大间隔分类器，这里的最大间隔指的是训练样本点到分隔超平面的间隔最大。在感知器中，没有考虑最大分隔这一条件，所以对于线性可分的数据集，会存在多个满足条件的分隔超平面，而在SVM中，加上“最大间隔这一条件”，使得分隔超平面唯一存在。</p>
<p>而在介绍SVM之前，需要了解拉格朗日乘子法的原理。</p>
<h1 id="拉格朗日乘子法">拉格朗日乘子法</h1>
<p>拉格朗日乘子法是凸优化中一个基础知识点，在高等数学中也接触过这一原理，但是在那里约束条件一般只是涉及到等式约束，其实在等式约束和不等式约束共存的前提下，整个过程的原理也是一样的。</p>
<h2 id="原始问题">原始问题</h2>
<p>$$ \min_{x \in R^n} f(x) \\<br>   s.t. c_i(x) \leq 0,i=1,2,\ldots,k\\<br>   \qquad h_j(x) = 0,j = 1,2,\ldots,l $$</p>
<p>其中，$f(x),c_i(x),h_j(x)$是定义在$R^n$上的连续可微函数。</p>
<p>解决这个优化问题可以采用拉格朗日乘子法，先引入拉格朗日函数：<br>$$L(x,\alpha,\beta) = f(x) + \alpha c(x) + \beta h(x)$$<br>其中，$\alpha,\beta$是k,l维的行向量，即拉格朗日乘子，且$\alpha \geq 0$。</p>
<p>考虑一下关于$x$的函数:<br>$$\theta (x) = \max_{\alpha,\beta;\alpha_i \geq 0} L(x,\alpha,\beta)$$</p>
<p>可以证明当x满足原始问题的约束条件时，$\theta (x) = f(x) $。（当约束条件的等号都成立时，$\theta (x)取得最大值$，反之，如果约束条件不满足，则\theta (x) 的取值趋向于无穷大）</p>
<p>此时，原始问题的极小化问题变为:</p>
<p>$$<br>\min_x \theta(x)<br>$$</p>
<h2 id="拉格朗日乘子法图解">拉格朗日乘子法图解</h2>
<p>想象一下目标函数关于变量的等高线，以二维变量为例，如下图所示（来源于维基百科）:<br><img src="https://s3-us-west-2.amazonaws.com/droplr.storage/files/acc_263367/CsFD?AWSAccessKeyId=AKIAJSVQN3Z4K7MT5U2A&amp;Expires=1401629870&amp;Signature=OjYyMqzDKIj%2FylGgFXAUuUegUzs%3D" alt=""></p>
<p>每条等高线对应着同一个目标函数值。约束条件的函数可以看成一条曲线，与相应等高线相交的点就是满足约束条件的目标值和相应的变量值。为了找到最优的目标值，需要使等高线与约束曲线相切。在相切点目标函数的梯度和约束条件函数的梯度是共线的，即$f(x)$的梯度等于 $\alpha h(x)$的梯度(假设只有等式约束)。</p>
<h2 id="对偶问题">对偶问题</h2>
<p>设函数$$D(\alpha,\beta) = min_{x} L(x,\alpha,\beta)$$</p>
<p>再极大化这一函数，可得原问题的对偶问题：<br>$$ \max_{\alpha,\beta;\alpha_i \geq 0} D(\alpha,\beta)\\<br>   s.t. \alpha_i \geq 0, i = 1,\ldots,k<br>$$</p>
<p>只要满足KKT条件，对偶问题的最优解和原始问题的最优解是一致的。在这里KKT条件就是</p>
<ol>
<li>$L(x,\alpha,\beta)$对x求导为0；</li>
<li>$h(x) = 0$; </li>
<li>$\alpha g(x) = 0$</li>
</ol>
<p>整个拉格朗日乘子法是解决带有等式和不等式约束条件的优化方法，特别是其将原问题变为对偶问题（最优解一致）能够很方便得对模型进行扩展，比如后面将要提到的核方法。</p>
<h1 id="SVM">SVM</h1>
<p>设分离超平面为:<br>$$w^Tx + b = 0$$</p>
<p>决策函数为:<br>$$f(x) = sign(w^Tx+b)$$</p>
<p>数据点到分离面的距离为$|w^T+b|$，当$w^T+b$的符号与标记$y$一致时表示分类正确，这样用$y(w^Tx+b)$来表示分类的正确性和确信度，符号为正表示分类正确，值的大小表示到分隔面的距离。</p>
<h2 id="函数间隔和几何间隔">函数间隔和几何间隔</h2>
<p>样本点的函数间隔为:<br>$$\hat \gamma_i = y_i(w^T x_i + b)$$</p>
<p>训练集的函数间隔就是:<br>$$\hat \gamma = \min_{i=1,\ldots,N} \hat \gamma_i$$</p>
<p>由于w,b成比例变化时，超平面不变，但是函数间隔变了，这样通过函数间隔无法刻画超平面的变化，需要一个其他的间隔来进行衡量，由此引出几何间隔。</p>
<p>样本点的几何间隔为：<br>$$Y_i = y_i(\frac{w^T}{||w^T||} x_i + \frac{b}{||w^T||})$$</p>
<p>训练集的间隔为：<br>$$Y = \min_{i=1,\ldots,N} Y_i$$</p>
<p>w,b成比例变化时，几何间隔不变，对应着超平面不变，所以可以通过w,b结合几何间隔来刻画超平面的位置。</p>
<p>函数间隔和几何间隔的关系很明显为$Y_i = \frac{\hat \gamma_i}{||W||},Y = \frac{\hat \gamma}{||W||}$。</p>
<h2 id="间隔最大化">间隔最大化</h2>
<p>现在的目的就是最大化训练集的几何间隔，所以优化函数如下：<br>$$\max_{w,b} Y \\<br>  s.t.\qquad y_i((\frac{w^T}{||w^T||} x_i + \frac{b}{||w^T||}) \geq Y,i=1,\dots,N$$</p>
<p>其中约束条件表示任何数据点的几何间隔至少是$Y$，注意那些离分隔面最近的点的距离就是$Y$，这些点被称作为支持向量，这也是支持向量机名称的来源。分隔面只由这些支持向量决定，训练集中其他数据点的变化对平面没有什么影响。</p>
<p>利用几何间隔和函数间隔的关系，用函数间隔来表示这一优化函数，如下：<br>$$\max_{w,b} \frac{\hat \gamma}{||w||} \\<br>  s.t.\qquad y_i((w^Tx_i + b) \geq \hat \gamma,i=1,\dots,N$$</p>
<p>前面说过函数间隔对于分隔面的位置没有影响，所以为了方便，令$\hat \gamma = 1$，同时为了规范化优化函数（一般是考虑最小化问题），可以将最大化$\frac{1}{||w||}$转化成最小化$\frac{1}{2}||w||^2$。于是SVM的线性可分优化问题最终确定为如下：<br>$$\min_{w,b}\frac{1}{2}||w||^2\\<br>s.t.\qquad y_i(w^Tx_i+b) - 1 \geq 0, i = 1,2,\ldots,N$$</p>
<p>求解这一优化问题的最优解，即是最优分离超平面，支持向量就是满足$y_i(w^Tx_i+b) - 1 = 0$的点。</p>
<h2 id="对偶求解">对偶求解</h2>
<p>求解前面的优化问题要利用到前面提到的朗格朗日乘子法，且需要转化成对偶问题。转化成对偶问题有两个好处：</p>
<ol>
<li>求解方便；</li>
<li>引入核函数，将SVM推广到非线性分类上去。</li>
</ol>
<p>根据前面介绍的对偶关系，对偶问题是一个极大极小值问题：<br>$$\max<em>{\alpha} \min</em>{w,b} L(w,b,\alpha)$$</p>
<p>所以需要先求$L(w,b,\alpha)$的极小值，再求对$\alpha$的极大。 </p>
<p>第一步：求解$\min_{w,b} L(w,b,\alpha)$ </p>
<p>分别对$w,b$求导并令其等于0, 然后代入拉格朗日函数得到</p>
<p>$$\min_{w,b} L(w,b,\alpha) = $$</p>
<p>$$-\frac{1}{2}\sum_{i=1}^N \sum_j^N \alpha_i\alpha_jy_iy_j(x_ix_j) +\sum_i^N\alpha_i$$</p>
<p>第二步：求$\min_{w,b} L(w,b,\alpha)$的极大，即对偶问题:</p>
<p>$$\max -\frac{1}{2}\sum_{i=1}^N \sum_j^N \alpha_i\alpha_jy_iy_j(x_ix_j) +\sum_i^N\alpha_i$$</p>
<p>$$s.t. \qquad \sum_{i=1}^N \alpha_iy_i = 0$$</p>
<p>$$\qquad \alpha_i \geq 0,i = 1,2,\ldots,N$$</p>
<h2 id="线性不可分问题">线性不可分问题</h2>
<p>前面是在线性可分的假设基础之上，如果数据不是线性可分的，这个时候需要引入松弛变量$\xi$，因为不管怎么分，都会有些数据是分错的，唯一能够做的就是使分错的数目最小（或者代价最小）。所以，优化函数变成了以下形式：<br>$$\min_{w,b,\xi} \frac{1}{2} ||w||^2+C\sum_i^N\xi_i$$</p>
<p>$$s.t. y_i(wx_i+b) \geq 1 - \xi_i,i=1,2,\ldots,N$$</p>
<p>$$\xi_i \geq 0,i=1,2,\ldots,N$$</p>
<h2 id="非线性支持向量机">非线性支持向量机</h2>
<p>有时候，数据在当前维度下不是线性可分的，但是将其映射到高维空间之后，数据变得线性可分。这个观念也可以从另一方面理解，如果数据线性不可分，但是可以画一条曲线将它们不同的类分离，而这条曲线可以理解成高维空间的一条直线，说明这些数据在高维空间是线性可分的。比方说$x^2+y^2 = 1$在平面空间内是一个圆，而在空间$(z_1=x^2,z_2 = y^2)$空间内就是一条$z_1+z_2 = 1$的直线。</p>
<p>解决这种问题就需要利用到核函数的概念。</p>
<h3 id="核函数">核函数</h3>
<p>低维到高维的变换需要一个映射函数：<br>$$\phi: X \rightarrow H$$</p>
<p>而核函数表示映射过到高维空间中数据点的内积，即函数$K(x,y)$满足：<br>$$K(x,y) = \phi(x)\cdot \phi(y), x,y \in X$$</p>
<p>其中$\phi(x)\cdot \phi(y)$表示内积。</p>
<p>如何利用核函数解决高维线性可分问题？</p>
<p>还记得前面提到的对偶问题的优势2吗？在对偶问题的目标函数中，存在$x_ix_j$这一因子，如果将其替换为$\phi(x_i)\cdot \phi(x_j)$，就可以直接应用核函数来将数据映射到高维空间进行线性划分。</p>
<p>核函数最直接的优势就是我们不需要去寻找映射函数$\phi$，而关心数据本身在高维空间的分布。</p>
<p>哪些函数能够成为核函数呢？需要满足正定核函数的条件。其实，平时利用的最多多的也就是那几个：高斯核、径向基核等等，如果需要实际体验，可以尝试libsvm这个软件，非常好用，有matlab接口(^_^)。</p>
<p>至此，整个SVM的初步流程理清了一遍，大致过程应该可以明了。</p>
<p>参考文献：  </p>
<ol>
<li>《统计机器学习》，李航  </li>
<li>《机器学习实战》，Peter Harrington</li>
</ol>
  
	</div>
		<footer class="article-footer clearfix">

  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习实战/">机器学习实战</a>
  </div>


<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/人工智能/">人工智能</a>
</div>



<div class="article-share" id="share">

  <div data-url="http://xiaojinwen.com/2014/06/01/svm/" data-title="支持向量机SVM | 风清阳明" data-tsina="null" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2014/06/08/adaboost/" title="AdaBoost">
  <strong>PREVIOUS:</strong><br/>
  <span>
  AdaBoost</span>
</a>
</div>


<div class="next">
<a href="/2014/05/28/logistic-regression/"  title="Logistic 回归">
 <strong>NEXT:</strong><br/> 
 <span>Logistic 回归
</span>
</a>
</div>

</nav>

	
<section class="comment">
	<div class="ds-thread"></div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#拉格朗日乘子法"><span class="toc-number">1.</span> <span class="toc-text">拉格朗日乘子法</span></a></li><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#原始问题"><span class="toc-number">1.1.</span> <span class="toc-text">原始问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#拉格朗日乘子法图解"><span class="toc-number">1.2.</span> <span class="toc-text">拉格朗日乘子法图解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#对偶问题"><span class="toc-number">1.3.</span> <span class="toc-text">对偶问题</span></a></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#SVM"><span class="toc-number">2.</span> <span class="toc-text">SVM</span></a></li><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#函数间隔和几何间隔"><span class="toc-number">2.1.</span> <span class="toc-text">函数间隔和几何间隔</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#间隔最大化"><span class="toc-number">2.2.</span> <span class="toc-text">间隔最大化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#对偶求解"><span class="toc-number">2.3.</span> <span class="toc-text">对偶求解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#线性不可分问题"><span class="toc-number">2.4.</span> <span class="toc-text">线性不可分问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#非线性支持向量机"><span class="toc-number">2.5.</span> <span class="toc-text">非线性支持向量机</span></a></li><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#核函数"><span class="toc-number">2.5.1.</span> <span class="toc-text">核函数</span></a></li></ol>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
			<li><a href="/categories/人工智能/" title="人工智能">人工智能<sup>7</sup></a></li>
		
			<li><a href="/categories/生活/" title="生活">生活<sup>1</sup></a></li>
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			<li><a href="/tags/机器学习实战/" title="机器学习实战">机器学习实战<sup>7</sup></a></li>
		
			<li><a href="/tags/说明/" title="说明">说明<sup>1</sup></a></li>
		
		</ul>
</div>


  <div class="rsspart">
	<a href="null" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<div class="social-font" class="clearfix">
		
		
		
		
	</div>
		<p class="copyright">Powered by <a href="http://zespia.tw/hexo/" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/A-limon/pacman" target="_blank" title="Pacman">Pacman</a> © 2014 
		
		<a href="http://xiaojinwen.com" target="_blank" title="Jinwen">Jinwen</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>


<script type="text/javascript">
  var duoshuoQuery = {short_name:"jinwen"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 




<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  </body>
</html>
