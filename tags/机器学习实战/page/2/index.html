<!DOCTYPE HTML><!-- _partial/head -->
<html>
<head>
  <meta charset="utf-8">
  
  <title>第 2 页 | 机器学习实战 | 风清阳明</title>
  <meta name="author" content="Jinwen">
  
  <meta name="description" content="互联网，机器学习，金融，生活">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="风清阳明"/>

  
    <meta property="og:image" content="undefined"/>
  

  
    <link rel="alternative" href="/true" title="风清阳明" type="application/atom+xml">
  
  
    <link href="/favicon.png" rel="icon">
  

  
  <link rel="stylesheet" href="/css/bootstrap.cerulean.min.css" media="screen" type="text/css">
  
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  <!-- _partial/post/google_analytics -->



</head>

 <body>
  <!-- _partial/navigation -->
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">风清阳明</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 <!-- tag -->
<!-- _partial/archive -->


<!-- archive.title -->
<div class="page-header">
  <h1 class="archive-title-tag archive-title-机器学习实战">机器学习实战</h1>
</div>

<div class="row page">
  <!-- cols -->
  
  <div class="col-md-9">
	

	  
	  <!-- display as entry -->
	  <div class="mypage">
	  
	  <!-- _partial/post/title -->
<div class="panel-heading">

	
	<!-- display as entry -->
		<h3 class="xtitle">
			<a href="/2014/05/25/desicison_tree/" >决策树</a>
			<span class="text-muted pull-right"><small> 5月 25 2014 </small></span>
		</h3>
	

</div>

	  <!-- _partial/post/entry -->
<div class="panel-body">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <p>每个数据都存有若干的特征值，这些特征值组成一个特征向量。但是，特征之间的等级关系是不一样的，就是说每个特征对于最终的类别影响是不一样的。比如说现在根据两种特征来判定某动物是不是属于鸟类，这两种特征分别是：是否能飞，是否有两只脚。因为鸟类都有翅膀，但不是只有鸟类才有翅膀，所以，根据我们的直觉，应该先看该动物是否有翅膀来进行判断。在这里，“飞”比“两只脚”的特征等级要高。</p>
<h1 id="介绍">介绍</h1>
<p>决策树就是一个根据特征的优先关系来进行分类的，假设目前的决策树已经形成，那么分类的时候就是依次从根节点遍历到叶子节点，每个节点代表一种特征，深度越小的节点优先级越高。</p>
<p>那么如何构造出相应的决策树呢？  </p>
<ol>
<li>我们要把训练数据进行合适的划分，这一步需要选出最好的特征（等级最高，后面介绍如何评价特征的好坏或等级）；  </li>
<li>以选出的特征作为节点，形成子树（有多少个特征值，就有多少颗子树）。如果所有的数据都是同一类，那么终止划分，否则，执行第3步骤；</li>
<li>在每个子树数据集中执行第1步骤。</li>
</ol>
<p>这是一个递归过程，反复执行构造步骤，直到数据都属于同一类。</p>
<h1 id="划分数据集">划分数据集</h1>
<p>选择一个最好的特征，根据这个特征值，将数据分成若干子集，这是划分数据集的过程。如何衡量一个特征是不是最好？需要利用信息论里面“熵”，这是量化信息的一个基本概念，衡量信息的期望值。</p>
<h2 id="计算熵">计算熵</h2>
<p>假设一共有n类，那么熵就是：<br>$$<br>H = -\sum_{i=1}^np(x_i)log_2p(x_i)<br>$$</p>
<p>代码如下：  </p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span>:</span>
    numEntries = len(dataSet)  <span class="comment"># 计算数据集的数量</span>
    labelCounts = {}           <span class="comment">#每个类别的数量</span>
    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet: 
        currentLabel = featVec[-<span class="number">1</span>]    <span class="comment"># 最后一列存的是类别</span>
        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys(): <span class="comment"># 第一次找到该类别</span>
            labelCounts[currentLabel] = <span class="number">0</span>
        labelCounts[currentLabel] += <span class="number">1</span>
    shannonEnt = <span class="number">0.0</span>
    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:
        prob = float(labelCounts[key])/numEntries   <span class="comment"># 用发生的频率近似概率</span>
        shannonEnt -= prob * log(prob,<span class="number">2</span>) <span class="comment">#log base 2  #熵的每一项</span>
    <span class="keyword">return</span> shannonEnt
</code></pre><h2 id="按给定特征划分数据集">按给定特征划分数据集</h2>
<p>当得出最优特征时，根据每个数据在当前特征的取值划分，取值相同的分为同一组，比如根据性别来分时，性别有两种取值，那么将当前数据集分成两组即可，所有男的分成一组，所有女的分成一组。</p>
<p>代码如下：</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet, axis, value)</span>:</span>
    <span class="comment"># axis 是最优特征，value是特征值</span>
    retDataSet = []   <span class="comment"># 新建一个数据列表</span>
    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:
        <span class="keyword">if</span> featVec[axis] == value:
            reducedFeatVec = featVec[:axis]     
            reducedFeatVec.extend(featVec[axis+<span class="number">1</span>:])
            retDataSet.append(reducedFeatVec)
    <span class="keyword">return</span> retDataSet
</code></pre><p>以上代码注意append和extend的差别，同一个列表功能一样，但是多个列表时，extend的元素会形成列表，append形成的元素和原先的列表元素相同。</p>
<h2 id="选择最优特征">选择最优特征</h2>
<p>最优特征的选取需要用到前面介绍的熵（信息期望）。熵是用来衡量信息多少的，即量化信息。熵越大，说明数据越乱，熵越小，说明数据越有序。最优特征需要保证划分后的数据比其他特征划分的数据更有序。因为有序程度可以通过熵来表示，所以实际中通过当前熵与划分熵的差来表示前后数据的变化，即信息增益。</p>
<p>代码如下：</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span><span class="params">(dataSet)</span>:</span>
    numFeatures = len(dataSet[<span class="number">0</span>]) - <span class="number">1</span>   <span class="comment"># 特征数要去掉最后的类别项</span>
    baseEntropy = calcShannonEnt(dataSet)  <span class="comment"># 数据集划分之前的熵</span>
    bestInfoGain = <span class="number">0.0</span>; bestFeature = -<span class="number">1</span>
    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):       <span class="comment"># 遍历所有特征以便选取最优特征</span>
        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]    <span class="comment">#抽取所有数据中的第i个特征 </span>
        uniqueVals = set(featList)     <span class="comment"># 集合中每一个元素都是唯一的，所以每个特征值也是唯一的</span>
        newEntropy = <span class="number">0.0</span>    
        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:
            subDataSet = splitDataSet(dataSet, i, value)  <span class="comment">#根据第i个特征的值value划分数据</span>
            prob = len(subDataSet)/float(len(dataSet)) <span class="comment"># 当前子集占所有集合的频率</span>
            newEntropy += prob * calcShannonEnt(subDataSet)  <span class="comment">#划分后数据集的熵</span>
        infoGain = baseEntropy - newEntropy     <span class="comment">#信息增益即是熵的减少</span>
        <span class="comment">#根据最大的信息增益选出最优特征</span>
        <span class="keyword">if</span> (infoGain &gt; bestInfoGain):       
            bestInfoGain = infoGain          
            bestFeature = i
    <span class="keyword">return</span> bestFeature      
</code></pre><h1 id="构造决策树">构造决策树</h1>
<p>构造决策树是一个递归过程，只要当前数据集中的实例不是同一类就需要继续划分。当然，有的时候特征已经选取完了，但是数据集中还是有实例不是同一类。这个时候就需要投票表决，所占实例的数量最多的一项作为该叶子节点的类别。</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classList)</span>:</span>
    classCount={}
    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:
        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys(): classCount[vote] = <span class="number">0</span>
        classCount[vote] += <span class="number">1</span>
    <span class="comment">#根据数量进行排序</span>
    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)  
    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]
</code></pre><p>创建决策树有两种情况终止：  </p>
<ol>
<li>所有特征已经选取完；  </li>
<li>所有实例属于同一类；</li>
</ol>
<p>代码如下：</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet,labels)</span>:</span>
    classList = [example[-<span class="number">1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]
    <span class="comment">#第一种终止情况</span>
    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList): 
        <span class="keyword">return</span> classList[<span class="number">0</span>]
    <span class="comment">#第二种终止情况</span>
    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>: 
        <span class="keyword">return</span> majorityCnt(classList)
    bestFeat = chooseBestFeatureToSplit(dataSet)
    bestFeatLabel = labels[bestFeat]
    myTree = {bestFeatLabel:{}}
    <span class="keyword">del</span>(labels[bestFeat])  
    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]
    uniqueVals = set(featValues)
    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:
        subLabels = labels[:]        
        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)
    <span class="keyword">return</span> myTree 
</code></pre><p>参考自<a href="http://www.manning.com/pharrington/" target="_blank">机器学习实战</a>第三章。</p>

	
	</div>
	

</div>
	<a type="button" href="/2014/05/25/desicison_tree/#more" class="btn btn-default more">阅读此文</a>
</div>

	  
	  <!-- _partial/post/title -->
<div class="panel-heading">

	
	<!-- display as entry -->
		<h3 class="xtitle">
			<a href="/2014/05/23/machinelearning_knn/" >k近邻算法</a>
			<span class="text-muted pull-right"><small> 5月 23 2014 </small></span>
		</h3>
	

</div>

	  <!-- _partial/post/entry -->
<div class="panel-body">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <p>这是一篇纯水文，只是想练习一下在博客中插入图片、公式、代码的效果。不过，如果有不知道kNN算法的童鞋，希望这篇博文能够帮助到你。</p>
<h1 id="介绍">介绍</h1>
<p>k近邻算法(kNN)算是机器学习里面最基本的分类算法了，基本思想就是近似的一些物体很有可能属于同一类。有句俗语说得好：“物以类聚，人以群分”，我们为了初步判断一个人是怎样的一个人，我们可以先看看他（她）交的朋友。 假设这个世界就只有三种类型的青年：普通青年、文艺青年和2B青年，对于我们认识的人，我们都知道他属于哪一类型的青年。现在，出现了一位新的青年Z，我们不认识他，那么如何判定他属于哪一种类型的青年呢？</p>
<p>这是机器学习的一个主要研究领域：分类。</p>
<p>对于kNN来说，其大致是这样解决这个问题的：首先我们根据我们认识的人得到每一种类型的人的一些特征。然后看Z和哪些人相像（通过比较他和已知青年的特征做比较，相同特征越多，二者最相像），最后我们根据和Z相像的人的类型大致判定Z的类型。 那么选多少人做比较呢？在kNN中，k就表示选k个人，根据实际应用而加以改变。</p>
<p>那么kNN就是这样的一个流程：   </p>
<ol>
<li>首先有个数据集，都是带属性特征和已知标签的（即知道他们的表现特征、属于哪一类型人）；  </li>
<li>然后根据新数据的特征，计算其和已知数据集的特征距离（多种衡量标准），找出最像的前k个数据（距离越小越相像）；</li>
<li>挑出前k个数据中数量最多的那一种类型，比方说选出的5个人中，有3位文艺青年、1位普通青年、1位2B青年，那么我们采用一种投票的性质，判定新数据表现为文艺青年。</li>
</ol>
<h1 id="模型">模型</h1>
<p>我们称已知类型的数据集为训练集X，标签为Y，新出现的数据是a。注意：X是一个向量集，a是一个向量，y看作是一个向量。那么，我们要得到a的类型pred(a)，根据kNN的思想，模型公式如下：</p>
<p>$$<br>pred(a) = argmax_i[number(i),i=1,\ldots,K]<br>$$<br>其中k表示所有种类的数目，number(i)表示第i种类型在前k个数据中所占的数目。挑选前k个数据是根据他们的特征距离来获得的。</p>
<p>训练数据都是已知标签的，如下图的A、B,特征向量的维度为2。</p>
<p><img src="https://s3-us-west-2.amazonaws.com/droplr.storage/files/acc_263367/JOzd?AWSAccessKeyId=AKIAJSVQN3Z4K7MT5U2A&amp;Expires=1400828892&amp;Signature=QJ%2F7AzfQrOrbt3LqEFj34kiFc%2FE%3D" alt=""></p>
<h1 id="实例">实例</h1>
<p>现在通过python实现kNN算法，详细介绍参见<a href="http://www.manning.com/pharrington/" target="_blank">机器学习实战</a>第二章。</p>
<p>引入模块:   </p>
<pre><code>&gt;&gt;&gt;<span class="keyword">import</span> kNN
</code></pre><p>创建带有属性特征和标签的数据，定义一个相关函数：</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span>
    group = array([[<span class="number">1.0</span>,<span class="number">1.1</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0.1</span>]])
    labels = [<span class="string">'A'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'B'</span>]
    <span class="keyword">return</span> group, labels
</code></pre><p>定义分类函数：</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">classify0</span><span class="params">(inX, dataSet, labels, k)</span>:</span>
    dataSetSize = dataSet.shape[<span class="number">0</span>]  <span class="comment">#得出训练数据的个数</span>
    diffMat = tile(inX, (dataSetSize,<span class="number">1</span>)) - dataSet <span class="comment"># 计算每个训练数据和待测试数据的差</span>
    sqDiffMat = diffMat**<span class="number">2</span> <span class="comment"># 距离平方</span>
    sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>) <span class="comment">#平方和</span>
    distances = sqDistances**<span class="number">0.5</span> <span class="comment"># 欧几里得距离</span>
    sortedDistIndicies = distances.argsort()   <span class="comment">#距离矩阵排序   </span>
    classCount={}   
    <span class="comment"># 选出距离前k小的数据       </span>
    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):
        voteIlabel = labels[sortedDistIndicies[i]]   <span class="comment">#记录第i小的数据标签，参与后面的投票。</span>
        classCount[voteIlabel] = classCount.get(voteIlabel,<span class="number">0</span>) + <span class="number">1</span>
    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)
    <span class="comment">#根据投票结果，得出票数最大的标签作为分类结果</span>
<span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]
</code></pre>
	
	</div>
	

</div>
	<a type="button" href="/2014/05/23/machinelearning_knn/#more" class="btn btn-default more">阅读此文</a>
</div>

	  
	  </div>
	  <div>
	  <center>
	  <!-- _partial/index_pagination -->
<div class="pagination">
<ul class="pagination">
	 
		
    	<li class="prev"><a href="/tags/机器学习实战/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i> 上一页</a></li>
  		

        <li><a href="/"><i class="fa fa-home"></i>Home</a></li>

		
          <li class="next disabled"><a>下一页<i class="fa fa-arrow-circle-o-right"></i></a></li>
        
	
</ul>
</div>

	  </center>
	  </div>

	  

</div> <!-- col-md-9/col-md-12 -->


<!-- _partial/sidebar -->
<div class="col-md-3">
	<div id="sidebar">
	
			<!-- _widget/search -->
<div class="form-group has-success has-feedback">
  <form action="//google.com/search" method="get" accept-charset="utf-8" >
    <input type="search" name="q" results="0" placeholder="搜索" class="form-control">
    <input type="hidden" name="q" value="site:xiaojinwen.com">
  </form>
</div>

		
			<!-- _widget/category -->

	<div class="widget">
		<h4>分类</h4>
		<ul class="tag_box inline list-unstyled">
		
			<li><a href="/categories/Python/">Python<span>1</span></a></li>
		
			<li><a href="/categories/人工智能/">人工智能<span>10</span></a></li>
		
			<li><a href="/categories/工作/">工作<span>1</span></a></li>
		
			<li><a href="/categories/机器学习/">机器学习<span>1</span></a></li>
		
			<li><a href="/categories/生活/">生活<span>1</span></a></li>
		
			<li><a href="/categories/读书/">读书<span>1</span></a></li>
		
		</ul>
	</div>


		
			<!-- _widget/tagcloud -->

	<div class="widget">
		<h4>标签云</h4>
		<ul class="tag_box inline list-unstyled">
		
			<li><a href="/tags/HMM/">HMM<span>3</span></a></li>
		
			<li><a href="/tags/王小波/">王小波<span>1</span></a></li>
		
			<li><a href="/tags/说明/">说明<span>1</span></a></li>
		
			<li><a href="/tags/Socket/">Socket<span>1</span></a></li>
		
			<li><a href="/tags/人工智能/">人工智能<span>1</span></a></li>
		
			<li><a href="/tags/机器学习实战/">机器学习实战<span>7</span></a></li>
		
			<li><a href="/tags/求职/">求职<span>1</span></a></li>
		
		
		</ul>
	</div>


		
			<!-- _widget/recent_posts -->

<div class="widget">
  <h4>最新文章</h4>
  <ul class="entry list-unstyled">
    
      <li>
        <a href="/2014/12/14/job_finding/" ><i class="fa fa-file-o"></i>求职小结</a>
      </li>
    
      <li>
        <a href="/2014/11/13/silent_majority/" ><i class="fa fa-file-o"></i>沉默的大多数</a>
      </li>
    
      <li>
        <a href="/2014/10/07/hmm_viterbi/" ><i class="fa fa-file-o"></i>隐马尔可夫模型（三）：Viterbi 算法</a>
      </li>
    
      <li>
        <a href="/2014/10/06/hmm_forward_algorithm/" ><i class="fa fa-file-o"></i>隐马尔可夫模型（二）：前向算法</a>
      </li>
    
      <li>
        <a href="/2014/09/05/hidden_morkov_model/" ><i class="fa fa-file-o"></i>隐马尔可夫模型（一）：介绍</a>
      </li>
    
  </ul>
</div>


		
			<!-- _widget/links -->

<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="http://blog.csdn.net/aivin24" title="Freewill's Github repository." target="_blank"]);">My CSDN Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->




	  </div>
    <footer> <!-- _partial/footer -->
<p>
  &copy; 2014 by Jinwen
  &nbsp;
  <span class="text-muted">Powered by:
    <a class="text-muted" href="http://zespia.tw/hexo/" target="_blank">Hexo</a>,
    <a class="text-muted" href="http://github.com/yieme/hexo-theme-freewill/">Freewill</a>
    &amp;
    <a class="text-muted" href="http://bootswatch.com/" target="_blank">Bootswatch <small>v3.2</small></a>
  </span>
</p>
 </footer>
  </div> <!-- container-narrow -->
  <!-- _partial/after_footer -->
<a id="gotop" href="#">
  <span>▲</span>
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body></html>
